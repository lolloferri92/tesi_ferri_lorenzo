\documentclass[12pt,a4paper]{report}
\usepackage[italian]{babel}
\usepackage{newlfont}
\usepackage{color}
\textwidth=450pt\oddsidemargin=0pt

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{setspace}

\begin{document}

% qui comincia il titolo
\begin{titlepage}
\begin{center}
{\Large{\textsc{Università degli studi di Roma $\cdot$ Tor Vergata}}} 
\rule[0.1cm]{15.8cm}{0.1mm}
\rule[0.5cm]{15.8cm}{0.6mm}
\\\vspace{3mm}

{\small{\bf Macroarea di Lettere e Filosofia \\ master in Sonic Arts}}

\end{center}

\vspace{23mm}

\begin{center}
\begin{spacing}{1.7}
\textcolor{black}{
\linespread{5}
{\LARGE{\bf 
FORMAT PER RIPRODUZIONE MULTICANALE:
}}\\ 
{\LARGE{\bf 
DALLO STEREO ALL'AUDIO 3D
}}}

\end{spacing}
\end{center}

\vspace{50mm} \par \noindent

\begin{minipage}[t]{0.47\textwidth}

{\large{\bf Relatore: \vspace{2mm}\\\textcolor{black}{
Prof. Giuseppe Silvi}\\\\

%\textcolor{red}{
%\bf Correlatore: (eventuale)
%\vspace{2mm}\\
%Prof./Dott. Nome Cognome\\\\}
}
}
\end{minipage}
%
\hfill
%
\begin{minipage}[t]{0.47\textwidth}\raggedleft \textcolor{black}{
{\large{\bf Presentata da:
\vspace{2mm}\\
%
% INSERIRE IL NOME DEL CANDIDATO
%
Lorenzo Ferri}}}
\end{minipage}

\vspace{17mm}

\begin{center}

{\large{%\bf Sessione \textcolor{black}{ I }
%\vspace{2mm}\\

Anno Accademico \textcolor{black}{2016/17}}}
\end{center}

\newpage\null\thispagestyle{empty}

\end{titlepage}
% qui finisce il titolo

\tableofcontents

\listoffigures


\addcontentsline{toc}{chapter}{Elenco delle figure}

\chapter*{Abstract}



\addcontentsline{toc}{chapter}{Abstract}


\chapter{I primi concetti sulla spazializzazione}

In questo capitolo inizieremo a parlare dei primi concetti riguardanti la spazializzazione audio partendo dai metodi classici di riproduzione fino ad elaborare i presupposti che portano alla necessità di dare un modo diverso di ricostruire uno spazio sonoro per le diverse esigenze.

\section{supporti fisici di riproduzione}

Partiamo con il fare una distinzione che ci servirà per sviluppare il ragionamento generale su due fronti distinti, infatti al momento i due principali metodi di riproduzione e di ascolto di materiale audio sono:

\begin{itemize}
\item \textbf{ascolto in cassa}: è un tipo di ascolto in cui l'informazione sonora viene tradotta da segnale elettrico ad acustico mediante uno o più altoparlanti posti a una certa distanza dall'ascoltatore e il fronte d'onda sono generato per arrivare alla persona deve percorrere un certo tratto in aria quindi diciamo che il sono generato vive nello spazio in cui sono collocati i diffusori e lo spazio stesso modifica l'informazione sonora
\item \textbf{ascolto in cuffia}: il concetto parte esattamente come quello esposto sopra in quanto anche qui ci sono la presenza di altoparlanti (uno per orecchio) l'unica differenza è che il segnale sonoro non vive nell'ambiente come succede per il caso sopra in quanto l'altoparlante è idealmente isolato dall'esterno e collocato relativamente molto vicino all'orecchio.



\end{itemize}
Entrambi i supporti fisici di riproduzione hanno il loro pregi e loro difetti che porta alla scelta di un supporto rispetto all'altro in base alle esigenze e alle necessità.


\section{Metodi classici di riproduzione}\label{metodi}

Ora passiamo a come possiamo sfruttare questi due supporti descritti.\\

Il modo più semplice e basilare con cui riusciamo a riprodurre del materiale audio è la \textbf{MONOFONIA}; essa è una tecnica attuabile solo con l'ausilio di una cassa acustica e sfrutta un solo canale audio \footnote{per canale audio si intende un supporto in cui "scorre" solo un'informazione sonora}
quindi di conseguenza nello spazio sonoro \footnote{per spazio sonoro si intende lo spazio acustico dove si generano e si propagano le onde sonore, nei nostri casi sarà sempre uno spazio chiuso quindi di conseguenza le leggi fisiche vigenti sono quelle degli spazi chiusi} vive una sola informazione sonora.

La sensazione che abbiamo ad ascoltare questo tipo di riproduzione è di sentire una sorgente puntiforme collocata nel punto in cui è messa la cassa.\\

Molto simile a questo metodo è il \textbf{DUALMONO} che utilizza sempre un solo canale audio ma questo viene sdoppiato e ripartito su due altoparlanti, questo fa si che si crei una sorgente fantasma \footnote{per sorgente fantasma si intende il fenomeno per cui se due sorgenti distanti tra di loro riproducono lo stesso segnale sonoro, la nostra percezione ci porta a pensare che la so} esattamente al centro tra la linea congiungente i due altoparlanti. 

In questo caso non ho utilizzato la parola "casse acustiche" in quanto possiamo utilizzare questo metodo sia in queste ultime che in cuffia avendo lo stesso risultato di percezione.\\

Ultimo metodo descritto è l'usuale \textbf{STEREO} in cui avendo a disposizione due speaker la sensazione di spazialità viene data dalla differenza di potenza del segnale inviata alle casse infatti se il segnale risulta più forte in una delle due sorgenti acustiche, la sorgente fantasma risulterà più spostata verso quest'ultima.

Questo avviene sia per casse in aria libera che per cuffie. \\

\[ \thicksim \blacklozenge \thicksim \]\\

Questi descritti sono i metodi principali di riproduzione in cui si comincia ad intravedere un primo approccio di spazializzazione	 sonora.





\chapter{Metodo Wave Field Syntesis}

Il metodo Wave Field Syntesis è un metodo diverso dai precedenti illustrati in quanto non si avvale della psicoacustica per "ingannare" la nostra mente e farci credere che stiamo ascoltando qualcosa che realmente non c'è, ma questa tecnica permette di ricreare fisicamente il fronte d'onda e quindi l'informazione sonora distribuita nello spazio acustico come se la sorgente che si vuole creare sia realmente collocata nel punto che vogliamo, per questo, forse anche impropriamente, catalogherò questo metodo come \textbf{AUDIO 3D}.\\

\section{Principio fisico alla base e algoritmo di implementazione}

Per riuscire a capire in fondo cosa sta alla base di questa tecnica bisognerà spiegare due semplici principi di meccanica ondulatoria: 

\begin{itemize}

\item \textbf{Principio di Huygens-Fresnel}: consideriamo una qualsiasi onda che abbia un fronte d'onda arbitrario, questa legge afferma che ogni punto del fronte d'onda in questione può essere visto come un'infinità di sorgenti secondarie puntiformi che generano un'infinità di fronti d'onda secondari in accordo in fase e in ampiezza e che sommando la totalità di questi ultimi si può ricostruire il fronte d'onda originale.



\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.35]{figures/huygens.jpg}
	\caption {Principio di Huygens-Fresnel} 
	\label{fig:huygens}
	\end{figure}

\item \textbf{Principio di Rayleigh}: questo principio riguarda la diffrazione in quanto se un fronte d'onda colpisce una fenditura di dimensioni paragonabili alla sua lunghezza d'onda, esso verrà ritrasmesso al di la della fenditura come se fosse una sorgente puntiforme.

\end{itemize}

Il salto concettuale ora è breve in quanto se una sorgente acustica reale emette un fronte d'onda ed esso impatta in una serie di fenditure disposte spazialmente in un modo preciso, il fronte d'onda passerà al di ognuna delle fenditure (principio di Rayleigh) e la somma della totalità dei fronti d'onda secondari ricreerà esattamente il fronte d'onda originale.

Ora l'unica cosa che è rimasta da fare è sostituire ogni fenditura con un altoparlante e far riprodurre ad esso un  segnale preciso che combinato con i segnali degli altri altoparlanti ricreerà fedelmente (almeno a livello concettuale) lo spazio sonoro che vogliamo ottenere

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.55]{figures/wfs.png}
	\caption {Salti concettuali della WFS} 
	\label{fig:wfs}
	\end{figure}
	

Ora le questioni che ci vengono naturali sono come e con quale segnale pilotare ogni altoparlante; le risposte possono essere molteplici ma tutte devono tener conto della geometria di progettazione del nostro sistema WFS, prendiamo uno dei casi più semplici.\\

\chapter{Algoritmo identificazione sorgenti}

In questo capitolo capiremo secondo quale logica riusciamo ad estrarre ed a capire in quale punto del piano sonoro è collocata ogni sorgente formante il contenuto che vogliamo esaminare, in secondo momento invece implementerò questo concetto in un basilare algoritmo capace di raggiungere lo scopo prefissato.

\section{Algoritmo Azimuth Discimination and Resyntesis ADRess} 

Nel capitolo \ref{metodi} abbiamo visto quali sono le differenze tra una riproduzione stereo, mono e dualmono, ora concentriamoci su come riuscire concettualmente ad isolare una sola sorgente in entrambi i casi.\\

Per quanto riguarda la riproduzione mono isolare risulta abbastanza difficile in quanto intuitivamente devo conoscere il contenuto del segnale o in alternativa il contenuto spettrale del segnale da estrapolare, questo è all'incirca quello che fa il nostro cervello quando sente qualcosa cioè cercà di ricosnoscere un'oggetto sonoro mediante certe regole quali la durata del suono, il contenuto armonico, il timbro ecc... e stessa cosa dobbiamo fare nell'algoritmo, cioè riconoscere tramite delle elaborazioni le ste stesse regole descritte prima.\\

Nel caso invece avessimo una riproduzione stereo in partenza una cosa ci viene in nostro aiuto, infatti la peculiarità della collocazione spaziale classica in un mix stereo è il fatto che una sorgente è collocata attraverso il panpot cioè una funzione basata sulla IID \footnote{La Interaural Intencity Difference è una funzione matematica che simula la differenza di intensità sonora percepita dalle nostre orecchie di una sorgente sonora posta ad un angolo $\theta$ dalla normale uscente di fronte alla testa dell'ascoltatore} che da l'illusione di sentire un suono in un punto della linea congiungente i due altoparlanti, in parole povere se uno stesso segnale è riprodotto con maggiore intensità in una cassa rispetto all'altra l'immagine virtuale di tale sorgente sarà avvertita più vicina alla casa con maggiore intensità di riproduzione; questo panpottaggio quindi sdoppia l'oggetto sonoro e lo ridistribuisce con intensità diverse sulle due casse ed è queso sdoppimento che ci viene in aiuto  infatti prima come ora non conoscevamo il contenuto da estrapolare ma in questo caso sappiamo che in divers misura il contenuto esiste in entrambi i canali e può essere in qualche maniera "matchato"; qua sta la difficoltà dell'algoritmo e per spiegarlo sarà comodo usare un'esempio.\\

Supponiamo di avere un file stereo in cui è stato registrato  





\begin{thebibliography}{}

\bibitem{wikihuygens} \textit{https://en.wikipedia.org/wiki/Huygens-Fresnel\_principle}
\bibitem{adress} \textit{https://riunet.upv.es/bitstream/handle/10251/12515/TesinaCobos.pdf}




\end{thebibliography}
\addcontentsline{toc} {chapter}{Bibliografia}


\end{document}

